# Arquitectura de Workers

## ğŸ“‹ Resumen

El sistema se divide en **3 procesos independientes** para asegurar escalabilidad y resiliencia:

1. **Express API** - Servidor HTTP que recibe webhooks
2. **ValidationWorker** - Valida mensajes y autoriza scraping
3. **ScraperWorker** - Ejecuta scraping con Playwright

## ğŸ”„ Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microsoft 365  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ POST /result/webhook
         â”‚ { messageId, clientState }
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Express API (index.ts)         â”‚
â”‚  - Valida clientState           â”‚
â”‚  - EnvÃ­a messageId a SQS        â”‚
â”‚  - Responde 202 inmediatamente  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQS_VALIDATION_QUEUE_URL       â”‚
â”‚  { messageId }                  â”‚
â”‚  VisibilityTimeout: 60s         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ polling cada 30s
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ValidationWorker               â”‚
â”‚  - Busca mensaje en Outlook     â”‚
â”‚  - Valida sender autorizado     â”‚
â”‚  - Guarda Result en BD          â”‚
â”‚  - EnvÃ­a a cola de scraping     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SQS_SCRAPER_QUEUE_URL          â”‚
â”‚  { messageId, sender, subject } â”‚
â”‚  VisibilityTimeout: 180s        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ polling cada 30s
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ScraperWorker                  â”‚
â”‚  - Ejecuta Playwright           â”‚
â”‚  - Login + 2FA                  â”‚
â”‚  - Busca email                  â”‚
â”‚  - Captura screenshot           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ CÃ³mo ejecutar

### Desarrollo (3 terminales)

```bash
# Terminal 1 - Express API
npm run dev

# Terminal 2 - ValidationWorker
npm run dev:validation-worker

# Terminal 3 - ScraperWorker
npm run dev:scraper-worker
```

### ProducciÃ³n (Docker/PM2)

```bash
# Con PM2
pm2 start dist/index.js --name api
pm2 start dist/validation-worker-main.js --name validation-worker
pm2 start dist/scraper-worker-main.js --name scraper-worker

# Con Docker Compose (crear docker-compose.yml)
docker-compose up -d
```

## ğŸ“¦ Colas SQS

### Cola 1: ValidaciÃ³n (`SQS_VALIDATION_QUEUE_URL`)

**PropÃ³sito:** Recibe messageId desde webhook  
**Timeout:** 60 segundos  
**Procesador:** ValidationWorker

**Payload:**

```json
{
  "messageId": "AAMkAGM2..."
}
```

**DLQ recomendada:** DespuÃ©s de 3 reintentos

### Cola 2: Scraping (`SQS_SCRAPER_QUEUE_URL`)

**PropÃ³sito:** Recibe datos para scraping  
**Timeout:** 180 segundos (3 minutos)  
**Procesador:** ScraperWorker

**Payload:**

```json
{
  "messageId": "AAMkAGM2...",
  "sender": "user@example.com",
  "subject": "Test Subject"
}
```

**DLQ recomendada:** DespuÃ©s de 2 reintentos

## ğŸ”§ Variables de Entorno

```env
# API Server
PORT=8080

# SQS - Colas separadas
SQS_VALIDATION_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/xxx/validation-queue
SQS_SCRAPER_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/xxx/scraper-queue

# AWS Credentials
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# Database
SUPABASE_URL=
SUPABASE_SERVICE_ROLE=

# Outlook
OUTLOOK_CLIENT_STATE=
APP_ID=
CLIENT_SECRET=
TENANT_ID=

# Scraper
SCRAPER_EMAIL=
SCRAPER_PASSWORD=
```

## âš ï¸ Ventajas de esta arquitectura

### âœ… Resiliencia

- Si Playwright crashea, no afecta Express
- Si Express se reinicia, workers siguen procesando
- Cada proceso puede reiniciarse independientemente

### âœ… Escalabilidad

- Puedes ejecutar mÃºltiples instancias de ScraperWorker
- ValidationWorker puede procesar cientos de mensajes/minuto
- Express responde en < 500ms al webhook

### âœ… Observabilidad

- Logs separados por proceso
- MÃ©tricas de SQS (mensajes en cola, tiempos de procesamiento)
- DLQ para mensajes fallidos

### âœ… Mantenibilidad

- CÃ³digo desacoplado
- FÃ¡cil de testear cada componente
- Cambios en scraping no afectan validaciÃ³n

## ğŸ› Troubleshooting

### Webhook responde lento

- âœ… Webhook solo envÃ­a a SQS (< 100ms)
- âŒ Si tarda mÃ¡s, revisar latencia de SQS

### Mensajes duplicados en scraping

- Verificar que ValidationWorker elimine mensajes despuÃ©s de procesar
- Revisar VisibilityTimeout de la cola de validaciÃ³n

### Scraping falla constantemente

- Revisar logs de ScraperWorker
- Aumentar VisibilityTimeout si tarda > 180s
- Verificar credenciales y 2FA

### Mensajes no se procesan

- Verificar que workers estÃ©n corriendo
- Revisar DLQ de cada cola
- Verificar credenciales de AWS

## ğŸ“Š Monitoreo recomendado

1. **CloudWatch Metrics para SQS:**

   - `ApproximateNumberOfMessagesVisible`
   - `ApproximateAgeOfOldestMessage`
   - `NumberOfMessagesSent`

2. **Logs estructurados:**

   - ValidationWorker: Success rate, processing time
   - ScraperWorker: Playwright execution time, errors

3. **Alertas:**
   - DLQ no vacÃ­a > 5 mensajes
   - ValidationWorker sin procesar por > 5 min
   - ScraperWorker tarda > 3 minutos

## ğŸ” Seguridad

- âœ… Webhook valida `clientState` antes de enviar a SQS
- âœ… ValidationWorker valida sender autorizado
- âœ… Credenciales solo en variables de entorno
- âœ… Cada worker solo tiene permisos necesarios
